---
title: "AnalysisExample_HK"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(tidyverse)
library(tidymodels)
library(skimr)
library(stringr)
library(corrplot)
library(RColorBrewer)
library("PerformanceAnalytics")
library("Hmisc")


flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

```

## BCI - SoA and SoO project analysis
First we need to import all data so we can connect(merge) it

```{r questionnaire, echo=FALSE}
questionnaire <- as_tibble(read.csv(file.path("./","questionnaire.csv")))

orderNumber<-rep(c(1,2,2,1),10)
questionnaire<-cbind(questionnaire,orderNumber)
#cleaning up your data to make it merge friendly
mood <- as_tibble(read.csv(file.path("./","Mood .csv"),stringsAsFactors=FALSE)) %>% mutate_if(is.character, stringr::str_replace_all, pattern = " ", replacement = "_")


  #feel free to break down this long command (run it with only the first lines and see how each additional pipe %>% changes the data)
mood <- mood %>%
  pivot_longer(cols = -X, names_to = "Participant") %>%  
  mutate_if(is.character, stringr::str_replace_all, pattern = " ", replacement = "_") %>%
  mutate_if(is.character, stringr::str_replace_all, pattern = "P", replacement = "") %>%
  mutate(Participant = as.numeric(Participant)) %>%
  pivot_wider(names_from = X)
 
```
 
```{r logData, echo=FALSE,message=F, warning=F,results='hide'}
 
 #main game event data
 df <-    list.files(recursive=TRUE ,path = "./data",
                    pattern = "*Game.csv", 
                    full.names = T) %>% 
  tibble(filename = .) %>%   
  mutate(file_contents = map(filename,~ read_csv(file.path(.),na = "NULL")))  %>% 
  unnest(cols=-filename) %>% 
  separate(col=filename,sep="/",into=c("start","folder","Participant","Level","filename")) %>%
  mutate(Participant=as.numeric(str_replace(Participant,"P","")), Level=as.factor(Level))

 # make timestamps more easily usable - express as seconds, set markers when input windows attempts start/end
 df <- df %>%
  # select(SessionID, Timestamp,Participant, Event, InputNumber,InputWindow,InputWindowOrder,TrialResult)%>%
  group_by(SessionID) %>%
  mutate(
    vis_t_time = as.POSIXlt(Timestamp, format = "%Y-%m-%d %H:%M:%OS"),
    hoursecs = (vis_t_time$hour - vis_t_time[1]$hour) * 60 * 60,
    minsecs = (vis_t_time$min - vis_t_time[1]$min) * 60,
    secs = (vis_t_time$sec - vis_t_time[1]$sec),
    timeInSecs = hoursecs + minsecs + secs,
    vis_t_time = NULL,
    hoursecs = NULL,
    minsecs = NULL,
    secs = NULL,
    GameIsOn = ifelse(Event == "GameRunning", 1, 0),
    GameIsOn = cumsum(GameIsOn),
    InputWindowNum = dplyr::lag(ifelse(Event == "GameDecision", 1, 0),default=0),
    InputWindowNum = cumsum(InputWindowNum)) %>%
   ungroup()
 
   
#get times for each input windows
df <- df %>%
  dplyr::group_by(SessionID, InputWindowNum) %>%
  mutate(startTime = min(timeInSecs), timeSinceIWstart = timeInSecs - startTime) %>%
  ungroup()

dfSummary <- df %>%
  dplyr::mutate(successes=ifelse(TrialResult == "AccInput", 1, 0))%>%
  dplyr::group_by(Participant, Level) %>%
  # select(Participant, Level, InputWindowNum, timeSinceIWstart, TrialResult) %>%
  dplyr::summarize(accPerc = sum(successes,na.rm = TRUE) / max(InputWindowNum), 
                          activateDelay = mean(timeSinceIWstart,na.rm = TRUE))

```
OK next data (code is identical apart from the file name patter)
```{r logMeta Data, echo=FALSE,message=F, warning=F,results='hide'}
  
dm <-     list.files(recursive=T,path = "./data",
                     pattern = "*Meta.csv", 
                     full.names = T) %>% 
  tibble(filename = .) %>%   
  mutate(file_contents = map(filename,~ read_csv(file.path(.),na = "NULL")))  %>% 
  unnest(cols=-filename)%>% 
  separate(col=filename,sep="/",into=c("start","folder","Participant","Level","filename")) %>%
  mutate(Participant=as.numeric(str_replace(Participant,"P","")))
```
Sample  data next (code is identical apart from the file name patter)
```{r logSampleData, echo=FALSE,message=F, warning=F,results='hide'}
 
ds <- list.files(recursive=T,path = "./data",
              pattern = "*Sample.csv", 
              full.names = T) %>% 
  tibble(filename = .) %>%   
  mutate(file_contents = map(filename,~ read_csv(file.path(.),na = "NULL")))  %>% 
  unnest(cols=-filename)%>% 
  separate(col=filename,sep="/",into=c("start","folder","Participant","Level","filename"))
 
```

## Initial analysis
```{r theBigMerge}
dfSummary <-dfSummary %>% merge(questionnaire) %>% merge(mood) 
dfSummary <-merge(dfSummary,questionnaire)

dfSummary %>%
  select(-Participant) %>%
  group_by(Level) %>%
  skim()

```

Overview
```{r pressure}
questionnaire %>%
  select(-Participant) %>%
  group_by(Level) %>%
  skim()
```

Correlation overview (you really need to reduce/collapse your Mood questionnaire )

```{r correlationStuff}
# check out this web page on easy summaries for correlations:
#http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

chart.Correlation(dfSummary[,-c(1,2,9:21)], histogram=TRUE, pch=19)


res2 <- Hmisc::rcorr(as.matrix(dfSummary[,-c(1,2,9:21)]))
flattenCorrMatrix(res2$r, res2$P)

corrplot(cor(dfSummary[dfSummary$Level=="Body",-c(1,2,9:21)]), type="upper",col=brewer.pal(n=8, name="RdYlBu"))
corrplot(cor(dfSummary[dfSummary$Level=="Blocks",-c(1,2,9:21)]), type="upper",col=brewer.pal(n=8, name="RdYlBu"))

dfSummary %>%
  filter(SoA > 2) %>%
  ggplot(aes(x = SoA, y = SoO, colour = Level)) +
  geom_jitter() +
  geom_smooth(method = "lm", fill = NA)


```
```{r PredictingFrustration}
options(pillar.sigfig = 5)
broom::tidy(lm(Frustration~Level*(SoA+SoO+accPerc+activateDelay),data=dfSummary))
broom::tidy(lm(Frustration~SoA+SoO+accPerc+activateDelay,data=dfSummary))
broom::tidy(lm(Frustration~Level,data=dfSummary)) %>%mutate_if(is.numeric, round, 5)
broom::tidy(lm(Frustration~Level*orderNumber,data=dfSummary))
broom::tidy(lm(SoO~Level*orderNumber,data=dfSummary))
broom::tidy(lm(SoA~Level*orderNumber,data=dfSummary))
broom::tidy(lm(Proprioception~orderNumber,data=dfSummary))
broom::tidy(lm(SoO~Level,data=dfSummary))



```

```{r Checking the effect of performance on SoA, SoO, Frustration and Proprioception}
# There seems to be a small effect(-0.3724182)(S = 10664, p-value = 0.0253) on frustration using Spearsman Rho 
cor.test(dfSummary$accPerc, dfSummary$SoA, method="spearman")
cor.test(dfSummary$accPerc, dfSummary$SoO, method="spearman")
cor.test(dfSummary$accPerc, dfSummary$Frustration, method="spearman")
ggplot(dfSummary, aes(x=accPerc,y=Frustration, colour=Level)) + geom_point() + geom_smooth(method = "lm", fill = NA)
cor.test(dfSummary$accPerc, dfSummary$Proprioception, method="spearman")

```


```{r Counter-balancing mood test}
#non-parametric data
 ParticipantOrder1 <- dfSummary %>% filter(orderNumber == 1)
 Body1 <- ParticipantOrder1 %>% filter(Level=="Body")
 Blocks1 <- ParticipantOrder1 %>% filter(Level=="Blocks")

 dfSummary %>%
  select(Participant, orderNumber,Level, Q1:Q13) %>%
  pivot_longer(cols = -c(Level, Participant,orderNumber)) %>%
  filter(orderNumber==1) %>% 
  group_by(name) %>% 
  summarise(p=wilcox.test(value~Level,paired=FALSE,exact=FALSE)$p.value) %>%View()
 
```

```{r Counter-balancing levels and performance}
#parametric data
#Histograms 
hist (as.numeric(Body1$accPerc), col="violet" , las =1, xlab="Body performance", main=" Performance as Percentages in Body1")
hist (as.numeric(Blocks1$accPerc), col="blue" , las =1, xlab="Blocks performance",main=" Performance as Percentages in Blocks1")
#ordernumber 1
#Use ParticipantOrder1 and Body,Blocks1
#Check for normality(Shapiro Wilks Test)
#The data is normal if the p-value is above 0.05.
SWTestBody1 <- shapiro.test(Body1$accPerc)
SWTestBlocks1 <- shapiro.test(Blocks1$accPerc)
#T test Welch's t-test (Does not require variance check)
t.test(Body1$accPerc, Blocks1$accPerc)

#parametric data
#Histograms 
hist (as.numeric(Body2$accPerc), col="green" , las =1,xlab="Body performance", main=" Performance as Percentages in Body2")
hist (as.numeric(Blocks2$accPerc), col="red" , las =1,xlab="Blocks performance", main=" Performance as Percentages in Blocks2")
#ordernumber 2
ParticipantOrder2 <- dfSummary %>% filter(orderNumber == 2)
Body2 <- ParticipantOrder2 %>% filter(Level=="Body")
Blocks2 <- ParticipantOrder2 %>% filter(Level=="Blocks")
#Check for normality(Shapiro Wilks Test)
SWTestBody2 <- shapiro.test(Body2$accPerc)
SWTestBlocks2 <- shapiro.test(Blocks2$accPerc)
#T test Welch's t-test (Does not require variance check)
t.test(Body2$accPerc, Blocks2$accPerc)
```

```{r Correlation test for SoO on all measurements}
#non-parametric data
#Cor.test(lvl1.SoO, lvl1.SoA)
cor.test(ParticipantOrder1$SoO, ParticipantOrder1$SoA, method="spearman", exact = FALSE)
#Cor.test(lvl2.SoO, lvl2.SoA)
cor.test(ParticipantOrder2$SoO, ParticipantOrder2$SoA, method="spearman", exact = FALSE)
#Cor.test(lvl1.SoO, lvl1.proprioception)
cor.test(ParticipantOrder1$SoO, ParticipantOrder1$Proprioception, method="spearman", exact = FALSE)
#Cor.test(lvl2.SoO, lvl2.proprioception)
cor.test(ParticipantOrder2$SoO, ParticipantOrder2$Proprioception, method="spearman", exact = FALSE)
#Cor.test(lvl1.SoO, lvl1.frustration)
cor.test(ParticipantOrder1$SoO, ParticipantOrder1$Frustration, method="spearman", exact = FALSE)
#Cor.test(lvl2.SoO, lvl2.frustration)
cor.test(ParticipantOrder2$SoO, ParticipantOrder2$Frustration, method="spearman", exact = FALSE)

```
