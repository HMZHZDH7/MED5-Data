---
title: "AnalysisExample_HK"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(tidyverse)
library(tidymodels)
library(skimr)
library(stringr)
library(corrplot)
library(RColorBrewer)
library("PerformanceAnalytics")
library("Hmisc")

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

```

## BCI - SoA and SoO project analysis
First we need to import all data so we can connect(merge) it

```{r questionnaire, echo=FALSE}
questionnaire <- as_tibble(read.csv(file.path("./","questionnaire.csv")))

#cleaning up your data to make it merge friendly
mood <- as_tibble(read.csv(file.path("./","Mood .csv"),stringsAsFactors=FALSE)) %>% mutate_if(is.character, stringr::str_replace_all, pattern = " ", replacement = "_")


  #feel free to break down this long command (run it with only the first lines and see how each additional pipe %>% changes the data)
mood <- mood %>%
  pivot_longer(cols = -X, names_to = "Participant") %>%  
  mutate_if(is.character, stringr::str_replace_all, pattern = " ", replacement = "_") %>%
  mutate_if(is.character, stringr::str_replace_all, pattern = "P", replacement = "") %>%
  mutate(Participant = as.numeric(Participant)) %>%
  pivot_wider(names_from = X)
 
 ```
 
 ```{r logData, echo=FALSE,message=F, warning=F,results='hide'}
 
 #main game event data
 df <-    list.files(recursive=TRUE ,path = "./data",
                    pattern = "*Game.csv", 
                    full.names = T) %>% 
  tibble(filename = .) %>%   
  mutate(file_contents = map(filename,~ read_csv(file.path(.),na = "NULL")))  %>% 
  unnest(cols=-filename) %>% 
  separate(col=filename,sep="/",into=c("start","folder","Participant","Level","filename")) %>%
  mutate(Participant=as.numeric(str_replace(Participant,"P","")), Level=as.factor(Level))

 # make timestamps more easily usable - express as seconds, set markers when input windows attempts start/end
 df <- df %>%
  # select(SessionID, Timestamp,Participant, Event, InputNumber,InputWindow,InputWindowOrder,TrialResult)%>%
  group_by(SessionID) %>%
  mutate(
    vis_t_time = as.POSIXlt(Timestamp, format = "%Y-%m-%d %H:%M:%OS"),
    hoursecs = (vis_t_time$hour - vis_t_time[1]$hour) * 60 * 60,
    minsecs = (vis_t_time$min - vis_t_time[1]$min) * 60,
    secs = (vis_t_time$sec - vis_t_time[1]$sec),
    timeInSecs = hoursecs + minsecs + secs,
    vis_t_time = NULL,
    hoursecs = NULL,
    minsecs = NULL,
    secs = NULL,
    GameIsOn = ifelse(Event == "GameRunning", 1, 0),
    GameIsOn = cumsum(GameIsOn),
    InputWindowNum = dplyr::lag(ifelse(Event == "GameDecision", 1, 0),default=0),
    InputWindowNum = cumsum(InputWindowNum)) %>%
   ungroup()
 
   
#get times for each input windows
df <- df %>%
  dplyr::group_by(SessionID, InputWindowNum) %>%
  mutate(startTime = min(timeInSecs), timeSinceIWstart = timeInSecs - startTime) %>%
  ungroup()

dfSummary <- df %>%
  dplyr::mutate(successes=ifelse(TrialResult == "AccInput", 1, 0))%>%
  dplyr::group_by(Participant, Level) %>%
  # select(Participant, Level, InputWindowNum, timeSinceIWstart, TrialResult) %>%
  dplyr::summarize(accPerc = sum(successes,na.rm = TRUE) / max(InputWindowNum), 
                          activateDelay = mean(timeSinceIWstart,na.rm = TRUE))

```
OK next data (code is identical apart from the file name patter)
 ```{r logMeta Data, echo=FALSE,message=F, warning=F,results='hide'}
  
dm <-     list.files(recursive=T,path = "./data",
                     pattern = "*Meta.csv", 
                     full.names = T) %>% 
  tibble(filename = .) %>%   
  mutate(file_contents = map(filename,~ read_csv(file.path(.),na = "NULL")))  %>% 
  unnest(cols=-filename)%>% 
  separate(col=filename,sep="/",into=c("start","folder","Participant","Level","filename")) %>%
  mutate(Participant=as.numeric(str_replace(Participant,"P","")))
```
Sample  data next (code is identical apart from the file name patter)
 ```{r logSampleData, echo=FALSE,message=F, warning=F,results='hide'}
 
ds <- list.files(recursive=T,path = "./data",
              pattern = "*Sample.csv", 
              full.names = T) %>% 
  tibble(filename = .) %>%   
  mutate(file_contents = map(filename,~ read_csv(file.path(.),na = "NULL")))  %>% 
  unnest(cols=-filename)%>% 
  separate(col=filename,sep="/",into=c("start","folder","Participant","Level","filename"))
 
```

## Initial analysis
```{r theBigMerge}
dfSummary <-dfSummary %>% merge(questionnaire) %>% merge(mood) 
dfSummary <-merge(dfSummary,questionnaire)

dfSummary %>%
  select(-Participant) %>%
  group_by(Level) %>%
  skim()

```

Overview
```{r pressure}
questionnaire %>%
  select(-Participant) %>%
  group_by(Level) %>%
  skim()
```

Correlation overview (you really need to reduce/collapse your Mood questionnaire )

```{r correlationStuff}
# check out this web page on easy summaries for correlations:
#http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

chart.Correlation(dfSummary[,-c(1,2,9:21)], histogram=TRUE, pch=19)


res2 <- Hmisc::rcorr(as.matrix(dfSummary[,-c(1,2,9:21)]))
flattenCorrMatrix(res2$r, res2$P)

corrplot(cor(dfSummary[dfSummary$Level=="lvl1",-c(1,2,9:21)]), type="upper",col=brewer.pal(n=8, name="RdYlBu"))
corrplot(cor(dfSummary[dfSummary$Level=="lvl2",-c(1,2,9:21)]), type="upper",col=brewer.pal(n=8, name="RdYlBu"))

dfSummary %>%
  filter(SoA > 2) %>%
  ggplot(aes(x = SoA, y = SoO, colour = Level)) +
  geom_jitter() +
  geom_smooth(method = "lm", fill = NA)


```
```{r PredictingFrustration}
options(pillar.sigfig = 5)
broom::tidy(lm(Frustration~Level*(SoA+SoO+accPerc+activateDelay),data=dfSummary))
broom::tidy(lm(Frustration~SoA+SoO+accPerc+activateDelay,data=dfSummary))
broom::tidy(lm(Frustration~Level,data=dfSummary)) %>%mutate_if(is.numeric, round, 5)

broom::tidy(lm(SoO~Level,data=dfSummary))


```
